apiVersion: apps/v1
kind: Deployment
metadata:
  name: chatbot

spec:
  replicas: 1
  selector:
    matchLabels:
      app: chatbot-app
  template:
    metadata:
      labels:
        app: chatbot-app
    spec:
      containers:
        - name: chatbot-app-container
          image: us-east4-docker.pkg.dev/hclsw-gcp-xai/img-repo/chatbot:0.3.1
          resources:
            requests:
              memory: 8Gi
              ephemeral-storage: 20Gi
            limits:
              memory: 8Gi
              ephemeral-storage: 20Gi
              nvidia.com/gpu: 1
          ports:
            - containerPort: 8501
              protocol: TCP
          volumeMounts:
            - mountPath: "/llama"
              name: llama-volume
      volumes:
        - name: llama-volume
          ephemeral:
            volumeClaimTemplate:
              metadata:
                labels:
                  type: chatbot-volume
              spec:
                accessModes: [ "ReadWriteOnce" ]
                storageClassName: "llama-storage-class"
                resources:
                  requests:
                    storage: 16Gi
      nodeSelector:
        cloud.google.com/gke-accelerator: "nvidia-tesla-t4"